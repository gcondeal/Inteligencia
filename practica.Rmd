---
title: "Práctica Inteligencia y Analítica de Negocios"
author: "Gustavo Conde Alvarez"
date: "mayo de 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(caret)
library(corrplot)
library(boot)
```

## Definición
Se trata de realizar el ajuste de una regresión múltiple sobre el conjunto de datos **candy-data.csv**. La variable de salida es el campo *winpercent*, y como variables explicativas se utilizaran todas las demás.

## Carga de datos
```{r cars}
candy.data <- read.csv("data/candy-data.csv", stringsAsFactors=TRUE)
```

## Tratamiento

### Separación en train y test
```{r}
trainIndex <- createDataPartition(candy.data$winpercent, p = .75,
list = FALSE,
times = 1)

candy.train=candy.data[trainIndex,]
candy.test=candy.data[-trainIndex,]

```

### a) Modelo múltiple
```{r}
modelo = glm(winpercent ~ chocolate + fruity + peanutyalmondy + caramel  + nougat + crispedricewafer + hard +  bar+ pluribus+ sugarpercent + pricepercent, data = candy.train)
summary(modelo)
modelo = glm(winpercent ~ chocolate + fruity + peanutyalmondy + sugarpercent, data = candy.train)
summary(modelo)
Yhat_train=predict(modelo,data.frame(candy.train[,-13]))
Yreal_train=candy.train[,"winpercent"]
ok_train=sum(Yhat_train-Yreal_train<1)/length(Yreal_train)

Yhat_test=predict(modelo,data.frame(candy.test[,-13]))
Yreal_test=candy.test[,"winpercent"]
ok_test=sum(Yhat_test-Yreal_test<1)/length(Yreal_test)

ok_train
ok_test
```

tras dejar las variables significativas en el modelo vemos que el AIC disminuye ligeramente, aunque el indice de acierto, ajustando con un margen de 1, es relativamente bajo, tanto en train como en test.


```{r}

newdatacor = cor(candy.data[,-1])
corrplot(newdatacor, method = "number")

```

La representación de la correlación de las varibles muestra que no existe correlación entre ninguna de las variables.


### b) aplicamos bootstrap para calcular el intervalo de confianza de los estimadores

```{r}


boot.fn=function(data,index)
  coefficients(glm(winpercent ~ chocolate + fruity + peanutyalmondy + sugarpercent, data =    data, subset=index))
set.seed(1)
boot(candy.data,boot.fn,1000)

```

### c) realizamos la validación k-fold

```{r}
cv.error.5=rep(0,5)
for (i in 1:5)
{
  modelo.fit=glm(winpercent~chocolate + fruity + peanutyalmondy + sugarpercent,data=candy.train)
  cv.error.5[i]=cv.glm(candy.train,modelo.fit,K=5)$delta[1]
}
cv.error.5
```


